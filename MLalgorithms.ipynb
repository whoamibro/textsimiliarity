{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats as sc\n",
    "import csv\n",
    "from konlpy.tag import Twitter\n",
    "\n",
    "twitter = Twitter()\n",
    "\n",
    "def tokenize(sentence):\n",
    "    return [''.join(m) for m in twitter.morphs(sentence)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open dataset file\n",
    "f = open('./PycharmProjects/textsimilarity/train_data.csv', 'r')\n",
    "datafile = csv.reader(f)\n",
    "\n",
    "# variable for extracted dataset from csv file\n",
    "dataset = [] \n",
    "\n",
    "# variable for analyzed morphemes by konlpy\n",
    "morphList = []\n",
    "\n",
    "# variable for comparing words in sentence with words in morphList\n",
    "tempList = []\n",
    "\n",
    "# listing sentences \n",
    "for data in datafile:\n",
    "    dataset.extend(data)\n",
    "\n",
    "f.close()\n",
    "\n",
    "# tokenizing and analyzing morpheme of train sentences \n",
    "tokenizedSet = [(tokenize(sentence)) for sentence in dataset]\n",
    "\n",
    "# extending all morphemes in all sentences into one list\n",
    "for tokenlist in tokenizedSet:\n",
    "    tempList.append(tokenlist)\n",
    "    morphList.extend(tokenlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "479\n"
     ]
    }
   ],
   "source": [
    "# Open test dataset file\n",
    "t = open('./PycharmProjects/textsimilarity/test_data.csv', 'r')\n",
    "testdatafile = csv.reader(t)\n",
    "\n",
    "# variable for extracted test dataset from csv file\n",
    "testdataset = [] \n",
    "\n",
    "# variable for comparing words in sentence with words in morphList\n",
    "testtempList = []\n",
    "\n",
    "# listing sentences \n",
    "for testdata in testdatafile:\n",
    "    testdataset.extend(testdata)\n",
    "\n",
    "t.close()\n",
    "\n",
    "# tokenizing and analyzing morpheme of test sentences \n",
    "tokenizedtestSet = [(tokenize(testsentence)) for testsentence in testdataset]\n",
    "\n",
    "# extending all morphemes in all sentences into one list\n",
    "for tokenlist in tokenizedtestSet:\n",
    "    testtempList.append(tokenlist)\n",
    "    morphList.extend(tokenlist)\n",
    "    \n",
    "#print(morphList)\n",
    "\n",
    "# eliminate overlapped data\n",
    "morphList = list(set(morphList))\n",
    "\n",
    "#print(tempList)\n",
    "#print(morphList)\n",
    "print(len((morphList)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "onehotvector = [[0 for vec in morphList] for sentence in dataset]\n",
    "\n",
    "# if sentence has word in morphList, change 0 to 1\n",
    "for sentence in range(0,len(dataset)):\n",
    "    \n",
    "    for morph in range(0,len(morphList)):\n",
    "        \n",
    "        for temp in range(0,len(tempList[sentence])):\n",
    "            \n",
    "            if morphList[morph] == tempList[sentence][temp]:\n",
    "                onehotvector[sentence][morph] = 1\n",
    "\n",
    "print(len(onehotvector))\n",
    "\n",
    "#print(len(testonehotvector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    }
   ],
   "source": [
    "testonehotvector = [[0 for vec in morphList] for sentence in testdataset]\n",
    "\n",
    "# if sentence has word in morphList, change 0 to 1\n",
    "for sentence in range(0,len(testdataset)):\n",
    "    \n",
    "    for morph in range(0,len(morphList)):\n",
    "        \n",
    "        for temp in range(0,len(testtempList[sentence])):\n",
    "            \n",
    "            if morphList[morph] == testtempList[sentence][temp]:\n",
    "                testonehotvector[sentence][morph] = 1\n",
    "\n",
    "print(len(testonehotvector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearsoncoefficient(sentence1, sentence2):\n",
    "    result = sc.stats.pearsonr(sentence1, sentence2)\n",
    "    #print(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosinesimilarity(sentence1, sentence2) :\n",
    "    vals = range(len(sentence1))\n",
    "    \n",
    "    sum1_sq = sum([sentence1[i]**2 for i in vals])\n",
    "    sum2_sq = sum([sentence2[i]**2 for i in vals])\n",
    "    \n",
    "    sumofproducts = sum([sentence1[i]*sentence2[i] for i in vals])\n",
    "\n",
    "    numerator = sumofproducts\n",
    "    denominator = pow(sum1_sq, 0.5) * pow(sum2_sq, 0.5)\n",
    "    \n",
    "    result = numerator/denominator\n",
    "    #print(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def levenshteindistance(sentence1, sentence2,key=hash):\n",
    "    rows = costmatrix(sentence1, sentence2, key)\n",
    "    edits = backtrace(sentence1, sentence2, rows, key)\n",
    "    #print(rows[-1][-1])\n",
    "    return rows[-1][-1], edits\n",
    "\n",
    "# making cost matrix of two sentences\n",
    "def costmatrix(sentence1, sentence2, key=hash):\n",
    "    rows = []\n",
    "    \n",
    "    previous_row = range(len(sentence2) + 1)\n",
    "    rows.append(list(previous_row))\n",
    "    \n",
    "    for i,c1 in enumerate(sentence1):\n",
    "        current_row = [i+1]\n",
    "        for j,c2 in enumerate(sentence2):\n",
    "            insertions = previous_row[j + 1] + 1\n",
    "            deletions = current_row[j] + 1\n",
    "            substitutions = previous_row[j] + (key(c1) != key(c2))\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    "        \n",
    "        rows.append(previous_row)\n",
    "    #print(rows)\n",
    "    return rows\n",
    "\n",
    "def backtrace(sentence1, sentence2, rows, key=hash):\n",
    "    i, j = len(sentence1), len(sentence2)\n",
    " \n",
    "    edits = []\n",
    " \n",
    "    while(not (i == 0  and j == 0)):\n",
    "        prev_cost = rows[i][j]\n",
    " \n",
    "        neighbors = []\n",
    " \n",
    "        if(i!=0 and j!=0):\n",
    "          neighbors.append(rows[i-1][j-1])\n",
    "        if(i!=0):\n",
    "          neighbors.append(rows[i-1][j])\n",
    "        if(j!=0):\n",
    "          neighbors.append(rows[i][j-1])\n",
    "     \n",
    "        min_cost = min(neighbors)\n",
    "     \n",
    "        if(min_cost == prev_cost):\n",
    "          i, j = i-1, j-1\n",
    "          edits.append({'type':'match', 'i':i, 'j':j})\n",
    "        elif(i!=0 and j!=0 and min_cost == rows[i-1][j-1]):\n",
    "          i, j = i-1, j-1\n",
    "          edits.append({'type':'substitution', 'i':i, 'j':j})\n",
    "        elif(i!=0 and min_cost == rows[i-1][j]):\n",
    "          i, j = i-1, j\n",
    "          edits.append({'type':'deletion', 'i':i, 'j':j})\n",
    "        elif(j!=0 and min_cost == rows[i][j-1]):\n",
    "          i, j = i, j-1\n",
    "          edits.append({'type':'insertion', 'i':i, 'j':j})\n",
    "     \n",
    "    edits.reverse()\n",
    "    #print(edits)\n",
    "    return edits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanimoto(sentence1, sentence2):\n",
    "    countIntersection = 0\n",
    "    count1insentence1 = 0   \n",
    "    count1insentence2 = 0\n",
    "    for index in range(0,len(sentence1)):\n",
    "        if sentence1[index] == 1:\n",
    "            count1insentence1 = count1insentence1 + 1\n",
    "        if sentence2[index] == 1:\n",
    "            count1insentence2 = count1insentence2 + 1\n",
    "        if (sentence1[index] == 1) and (sentence2[index] == 1):\n",
    "            countIntersection = countIntersection + 1\n",
    "    \n",
    "    return (float)(countIntersection/(count1insentence1+count1insentence2-countIntersection))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(sentence1, sentence2):\n",
    "    countIntersection = 0\n",
    "    count10case = 0\n",
    "    count01case = 0\n",
    "    for index in range(0,len(sentence1)):\n",
    "        if sentence1[index] == 1 :\n",
    "            if sentence2[index] == 1:\n",
    "                countIntersection = countIntersection + 1\n",
    "            elif sentence2[index] == 0:\n",
    "                count10case = count10case + 1\n",
    "        elif (sentence1[index] == 0) and (sentence2[index] == 1):\n",
    "            count01case = count01case + 1\n",
    "    return (float)(countIntersection/(count10case+count01case+countIntersection))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    }
   ],
   "source": [
    "score_list_pearson = [[pearsoncoefficient(testsentence,sentence)[0] for sentence in onehotvector] for testsentence in testonehotvector]\n",
    "print(len(score_list_pearson))\n",
    "score_list_cosine = [[cosinesimilarity(testsentence,sentence) for sentence in onehotvector] for testsentence in testonehotvector]\n",
    "print(len(score_list_cosine))\n",
    "score_list_tanimoto = [[tanimoto(testsentence, sentence) for sentence in onehotvector] for testsentence in testonehotvector]\n",
    "print(len(score_list_tanimoto))\n",
    "score_list_jaccard = [[jaccard(testsentence, sentence) for sentence in onehotvector] for testsentence in testonehotvector]\n",
    "print(len(score_list_jaccard))\n",
    "score_list_levenshtein = [[levenshteindistance(testsentence, sentence)[0] for sentence in onehotvector] for testsentence in testonehotvector]\n",
    "print(len(score_list_levenshtein))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 15, 8, 15, 28, 68, 68, 68, 113, 29, 30, 51, 54, 208, 49, 52, 49, 52, 49, 85, 60, 73, 84, 284, 284, 89, 33, 64, 46, 176, 90, 93, 121, 146, 119, 21, 135, 78, 115, 77, 120, 147, 179, 121, 132, 52, 146, 141, 55, 146, 176, 158, 143, 177, 151, 175, 162, 66, 176, 180, 204, 253, 193, 192, 84, 191, 206, 191, 191, 210, 233, 236, 210, 25, 10, 258, 238, 115, 221, 240, 258, 264, 264, 264, 176, 244, 258, 256, 290, 270, 285, 295, 286, 299, 258, 63, 285, 84, 285]\n99\n[0, 15, 8, 0, 28, 68, 68, 9, 113, 29, 30, 51, 54, 208, 49, 52, 49, 52, 49, 85, 60, 73, 84, 284, 284, 89, 33, 64, 46, 176, 90, 93, 121, 146, 119, 21, 135, 78, 115, 77, 120, 147, 164, 121, 132, 52, 146, 141, 55, 146, 176, 158, 143, 177, 179, 175, 162, 66, 176, 180, 204, 253, 193, 192, 84, 191, 206, 191, 191, 210, 233, 236, 210, 25, 10, 10, 238, 115, 221, 240, 258, 264, 264, 264, 176, 244, 258, 256, 290, 270, 285, 295, 281, 299, 258, 63, 285, 84, 285]\n99\n[0, 15, 8, 175, 28, 175, 175, 175, 220, 29, 30, 54, 44, 208, 49, 52, 49, 52, 49, 43, 60, 73, 84, 284, 284, 64, 33, 64, 64, 176, 90, 93, 54, 33, 32, 33, 132, 78, 115, 64, 120, 147, 151, 121, 132, 52, 133, 141, 55, 33, 176, 176, 168, 56, 151, 175, 162, 66, 176, 180, 204, 176, 193, 192, 84, 191, 206, 191, 191, 210, 233, 64, 227, 25, 10, 258, 64, 40, 221, 240, 258, 264, 264, 264, 176, 244, 258, 56, 56, 270, 285, 295, 281, 81, 176, 64, 285, 84, 285]\n99\n[0, 15, 8, 0, 28, 68, 68, 175, 4, 29, 30, 51, 54, 208, 49, 52, 49, 52, 49, 85, 60, 73, 84, 284, 284, 89, 33, 64, 46, 176, 90, 93, 121, 146, 119, 21, 135, 104, 115, 77, 120, 147, 164, 121, 132, 52, 146, 141, 55, 146, 176, 158, 143, 177, 179, 175, 162, 66, 176, 180, 204, 253, 193, 192, 84, 191, 206, 191, 191, 210, 233, 236, 210, 25, 10, 10, 238, 115, 221, 240, 258, 264, 264, 264, 176, 244, 258, 256, 290, 270, 285, 295, 281, 299, 258, 63, 285, 84, 285]\n99\n[0, 15, 8, 0, 28, 68, 68, 175, 4, 29, 30, 51, 54, 208, 49, 52, 49, 52, 49, 85, 60, 73, 84, 284, 284, 89, 33, 64, 46, 176, 90, 93, 121, 146, 119, 21, 135, 104, 115, 77, 120, 147, 164, 121, 132, 52, 146, 141, 55, 146, 176, 158, 143, 177, 179, 175, 162, 66, 176, 180, 204, 253, 193, 192, 84, 191, 206, 191, 191, 210, 233, 236, 210, 25, 10, 10, 238, 115, 221, 240, 258, 264, 264, 264, 176, 244, 258, 256, 290, 270, 285, 295, 281, 299, 258, 63, 285, 84, 285]\n99\n"
     ]
    }
   ],
   "source": [
    "pearson_result = []\n",
    "cosine_result = []\n",
    "levenshtein_result = []\n",
    "tanimoto_result = []\n",
    "jaccard_result = []\n",
    "\n",
    "for index in range(0,len(testonehotvector)):\n",
    "    pearson_result.append(score_list_pearson[index].index(max(score_list_pearson[index])))\n",
    "    cosine_result.append(score_list_cosine[index].index(max(score_list_cosine[index])))\n",
    "    levenshtein_result.append(score_list_levenshtein[index].index(min(score_list_levenshtein[index])))\n",
    "    tanimoto_result.append(score_list_tanimoto[index].index(max(score_list_tanimoto[index])))\n",
    "    jaccard_result.append(score_list_jaccard[index].index(max(score_list_jaccard[index])))\n",
    "\n",
    "print(pearson_result)\n",
    "print(len(pearson_result))\n",
    "\n",
    "print(cosine_result)\n",
    "print(len(cosine_result))\n",
    "\n",
    "print(levenshtein_result)\n",
    "print(len(levenshtein_result))\n",
    "\n",
    "print(tanimoto_result)\n",
    "print(len(tanimoto_result))\n",
    "\n",
    "print(jaccard_result)\n",
    "print(len(jaccard_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n63\n57\n64\n64\n"
     ]
    }
   ],
   "source": [
    "pearson_score = 0\n",
    "cosine_score = 0\n",
    "tanimoto_score = 0\n",
    "jaccard_score = 0\n",
    "levenshtein_score = 0 \n",
    "\n",
    "for index in range(0,len(pearson_result)):\n",
    "    first_index = (int)(index/10)\n",
    "    if pearson_result[index] >= first_index*30 and pearson_result[index] < (first_index+1)*30:\n",
    "        pearson_score = pearson_score + 1\n",
    "        \n",
    "print(pearson_score)\n",
    "\n",
    "for index in range(0,len(cosine_result)):\n",
    "    first_index = (int)(index/10)\n",
    "    if cosine_result[index] >= first_index*30 and cosine_result[index] < (first_index+1)*30:\n",
    "        cosine_score = cosine_score + 1\n",
    "        \n",
    "print(cosine_score)\n",
    "\n",
    "for index in range(0,len(levenshtein_result)):\n",
    "    first_index = (int) (index/10)\n",
    "    if levenshtein_result[index] >= first_index*30 and levenshtein_result[index] < (first_index+1)*30:\n",
    "        levenshtein_score = levenshtein_score + 1\n",
    "        \n",
    "print(levenshtein_score)\n",
    "\n",
    "for index in range(0, len(tanimoto_result)):\n",
    "    first_index = (int) (index/10)\n",
    "    if tanimoto_result[index] >= first_index*30 and tanimoto_result[index] < (first_index+1)*30:\n",
    "        tanimoto_score = tanimoto_score + 1\n",
    "        \n",
    "print(tanimoto_score)\n",
    "\n",
    "for index in range(0, len(jaccard_result)):\n",
    "    first_index = (int) (index/10)\n",
    "    if jaccard_result[index] >= first_index*30 and jaccard_result[index] < (first_index+1)*30:\n",
    "        jaccard_score = jaccard_score + 1\n",
    "        \n",
    "print(jaccard_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
